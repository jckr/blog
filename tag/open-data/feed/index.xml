<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>open data &#8211; jckr.github.io/blog</title>
	<atom:link href="http://localhost/tag/open-data/feed/" rel="self" type="application/rss+xml" />
	<link>/</link>
	<description>Just another WordPress site</description>
	<lastBuildDate>Wed, 17 Aug 2016 05:36:39 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>hourly</sy:updatePeriod>
	<sy:updateFrequency>1</sy:updateFrequency>
	<generator>https://wordpress.org/?v=4.6.10</generator>
	<item>
		<title>Open data and data journalism</title>
		<link>/2011/10/14/open-data-and-data-journalism/</link>
		<comments>/2011/10/14/open-data-and-data-journalism/#respond</comments>
		<pubDate>Fri, 14 Oct 2011 10:50:11 +0000</pubDate>
		<dc:creator><![CDATA[jerome]]></dc:creator>
				<category><![CDATA[presentation]]></category>
		<category><![CDATA[caroline goulard]]></category>
		<category><![CDATA[cecile dehesdin]]></category>
		<category><![CDATA[data journalism]]></category>
		<category><![CDATA[data veyes]]></category>
		<category><![CDATA[eric mettoux]]></category>
		<category><![CDATA[etalab]]></category>
		<category><![CDATA[fabrice epelboin]]></category>
		<category><![CDATA[fhimt]]></category>
		<category><![CDATA[françois prosper]]></category>
		<category><![CDATA[guardian]]></category>
		<category><![CDATA[journalism]]></category>
		<category><![CDATA[karen bastien]]></category>
		<category><![CDATA[lexpress]]></category>
		<category><![CDATA[open data]]></category>
		<category><![CDATA[partikuls]]></category>
		<category><![CDATA[pierre falga]]></category>
		<category><![CDATA[simon rogers]]></category>
		<category><![CDATA[slate]]></category>
		<category><![CDATA[storytelling with data]]></category>
		<category><![CDATA[tunisia]]></category>
		<category><![CDATA[we_do_data]]></category>

		<guid isPermaLink="false">http://jckr.github.io/blog/?p=1060</guid>
		<description><![CDATA[Yesterday I attended a workshop organized by Etalab on data journalism. Since open data, data visualization and storytelling with data are my 3 work interests I could not just be found elsewhere that day. Interestingly, while speakers and attendants were very much discussing the same subject, what was said (or inferred in questions asked) was <a class="read-more" href="/2011/10/14/open-data-and-data-journalism/">&#8230;&#160;<span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>Yesterday I attended a workshop organized by <a href="http://www.etalab.gouv.fr/article-4eme-atelier-de-travail-datajournalisme-86096912.html">Etalab on data journalism</a>. Since open data, data visualization and storytelling with data are my 3 work interests I could not just be found elsewhere that day.</p>
<p>Interestingly, while speakers and attendants were very much discussing the same subject, what was said (or inferred in questions asked) was very different. On some topics participants presented opposite opinions,  while on others there was a strong agreement.</p>
<h2>Inspiration and enthusiasm</h2>
<p>That was definitely the common denominator across presentations. </p>
<p>In short: <strong>visualization + journalism = win</strong>. </p>
<p>Every presenter, <a href="http://www.twitter.com/!#/dataveyes">@dataveyes</a>, Pierre Falga, <a href="http://www.twitter.com/!#/datastore">@datastore</a>, <a href="http://www.twitter.com/!#/sayseal">@sayseal</a>, <a href="http://www.twitter.com/!#/we_do_data">@we_do_data</a> and <a href="http://www.twitter.com/!#/epelboin">@epelboin</a> all showed are talked about things which were pretty awesome and which would have not been possible with data or visualization. While I was familiar with the other examples, I was most fired up by Fabrice Epelboin&#8217;s presentation of Tunisian media, Fhimt.com and its <a href="http://dataviz.fhimt.com/">dataviz gallery</a>.</p>
<p>What was interesting was how it was easy to tell a memorable story with the support of data. I think for the picture to be complete you also have to include in the big picture the viewer&#8217;s assumption and the presenter/journalist narration. One example which was shown by both Caroline Goulard and Simon Rogers is the relationship between tweets and UK riots.</p>
<p>The unsaid assumption was that social media have helped organize the riots.</p>
<p><a href="http://www.guardian.co.uk/uk/interactive/2011/aug/24/riots-twitter-traffic-interactive"><img class="aligncenter size-full wp-image-1061" title="guardian" src="http://jckr.github.io/blog/wp-content/uploads/2011/10/guardian.png" alt="" /></a></p>
<p>Facts in hand, in turns out that the bulks of the tweets related to a  riot happened after, not before, the event.  So the narrator help us conclude that riot caused tweets rather than the other way around.</p>
<p>Another example from <a href="http://www.fhimt.com/">fhimt.com</a>:<br />
We assume that tertiary graduates have better job prospects than those with less education.<br />
<a href="http://dataviz.fhimt.com/wp-content/uploads/2011/10/chomage.001.jpg"><img class="alignnone size-full wp-image-380" title="chomage.001" src="http://dataviz.fhimt.com/wp-content/uploads/2011/10/chomage.001.jpg" alt="" width="819" height="614"></a><br />
This isn&#8217;t the case in Tunisia where there graduates endure a 23% unemployment rate, while the rate for those who haven&#8217;t completed primary school is around 5%.<br />
Comment by Fabrice Epelboin: the only thing left to do for them is prepare the revolution. I find this a very clear and rational explanation of the arab spring, in contrast with how television presented those events.</p>
<h2>Is this difficult?</h2>
<h3>It requires work</h3>
<p>And no one denies this. Cécile Dehesdin and We Do Data presented us their work process, from the original idea to the final piece. Cécile would stress more the usage aspects while Karen and François emphasized the benefits of illustration and aesthetics to the final result. They both tried to convey us the amount of time and effort it takes to achieve something. </p>
<h3>and ressources&#8230; or not</h3>
<p>Then Pierre Falga and Simon Rogers gave somewhat conflicting views of the inner working of a newsroom. While Simon Rogers depicts the process as relatively effortless and quick thanks to freely available tools, Pierre Falga&#8217;s views where that an online newsroom&#8217;s resources were very thin, which prevented most media from fully embracing data journalism. To nuance Rogers position and bring it closer to consensus, he argues that <strong>the work-intensive part is</strong> not the output proper, but rather <strong>the data collection</strong>, and like Cécile and Pierre he had his share of horror stories on this front. </p>
<h2>Thank you, open data</h2>
<p>All presenters were grateful for data being increasingly accessible through open data initiatives. Not all is rosy in dataland, however, as institutions here and there are not all excited about doing the prospects of spending their own resources to retrieve data for journalists &#8211; even in the case where they are legally forced to.<br />
While <strong>data journalism obviously need open data, the reverse is possibly truer</strong> &#8211; that may be the motive for Etalab to organize the event. So far, official data portals haven&#8217;t proved to be directly useful to the concerned citizen, so it is those who are able to utilize those free data and turn them into attention-arresting stories that give them a purpose and demonstrate very visibly that the open data process truly benefits all. </p>
<h2>Is there a demand for data journalism?</h2>
<p>Presenters didn&#8217;t all address this question frontally but seemed to have mixed opinions about that. The guardian has been resorting to data journalism for over one century and gave no impression to ever have reconsidered the question. Others in the rooms, including attendants, had less faith on the matter. Pierre Falga and Eric Mettoux from lexpress.fr admitted their share of responsibility as that demand is largely dependent on the supply of quality material from existing media. </p>
<p>More fundamentally, I see that the mix of data visualization and communication is commonly referred to as data journalism which may be a slight over simplification.<br />
<strong>Why would the task of communicating with data visualization be restricted to journalists or media?</strong> <strong>Companies and government</strong> agencies alike have considerable budgets devoted to communication. IMO they <strong>should be the ones driving that effort</strong>. To a curious audience, that is, to the people who are actively seeking information on a certain topic, data visualization answers can be insanely more powerful and cost-effective than classic communication tailored for a more passive receiver. </p>
]]></content:encoded>
			<wfw:commentRss>/2011/10/14/open-data-and-data-journalism/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>New data services 3: data.gov</title>
		<link>/2009/06/30/new-data-services-3-datagov/</link>
		<comments>/2009/06/30/new-data-services-3-datagov/#respond</comments>
		<pubDate>Tue, 30 Jun 2009 16:31:12 +0000</pubDate>
		<dc:creator><![CDATA[jerome]]></dc:creator>
				<category><![CDATA[data publishing]]></category>
		<category><![CDATA[data visualization]]></category>
		<category><![CDATA[data formats]]></category>
		<category><![CDATA[data.gov]]></category>
		<category><![CDATA[finding data]]></category>
		<category><![CDATA[government]]></category>
		<category><![CDATA[open data]]></category>
		<category><![CDATA[xml]]></category>

		<guid isPermaLink="false">http://jckr.github.io/blog/?p=150</guid>
		<description><![CDATA[The United States are the only western country without a centralized data office. Instead, official statistics are produced by well over 100 agencies. This makes obtaining official US data difficult, and that&#8217;s somewhat of a paradox because in most cases, these data are public and free. Of course, with data coming from so many sources, <a class="read-more" href="/2009/06/30/new-data-services-3-datagov/">&#8230;&#160;<span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>The United States are the only western country without a centralized data office. Instead, official statistics are produced by well over 100 agencies. This makes obtaining official US data difficult, and that&#8217;s somewhat of a paradox because in most cases, these data are public and free. Of course, with data coming from so many sources, they are also in a variety of shapes and sizes. Says <a href="http://www.wired.com/politics/onlinerights/magazine/17-07/mf_cio">Wired</a>,</p>
<blockquote><p>Until now, the US government&#8217;s default position has been: If you can&#8217;t keep data secret, at least hide it on one of 24,000 federal Web sites, preferably in an incompatible or obsolete format.</p></blockquote>
<p>A commitment made by the Obama administration was to tackle this and make data more widely available. To that end, a data portal was announced in early April and data.gov was officially launched end of May.</p>
<p>Data.gov is three things in one.</p>
<p>A sign that this administration wants to make the data more accessible, especially to <strong>developers</strong>.</p>
<p>A shift towards open formats, such as XML.</p>
<p>A catalogue of datasets published by US government agencies.</p>
<p>The rationale is that with data.gov, data are available to wider audiences. There&#8217;s a fallacy in that, because the layperson cannot do much with an ESRI file. But hopefully, someone will and may build something out of it for the good of the community.</p>
<p>The aspect I found most interesting is the catalogue proper. For each indexed dataset, data.gov builds an abstract, inspired by the Dublin-Core Metadata Initiative, with fields such as authoring agency, keywords, units, and the like. This, in itself, is not a technological breakthrough but imagine if all the datasets produced by all the agencies were described in such a uniform fashion. Then, retrieving data would be a breeze.</p>
<p>Note that data.gov does not store the datasets. They provide a store-front which then redirects users to the proper location once a dataset has been selected.</p>
<p>There have been other, similar initiatives. Fedstats.gov, allegedly, provided a link to every statistical item produced by the federal government. By their own admission, the home page was last updated in 2007, and its overall design hasn&#8217;t changed much since its <a href="http://www.fedstats.gov/osspress.html">launch</a> by the Clinton administration in 1997 (a laudable effort at the time). Another initiative, <a href="http://usgovxml.com/">http://usgovxml.com/</a>, is a private portal to all data available in XML format.</p>
<p>So, back to &#8220;<strong>find </strong>&gt; <strong>access </strong>&gt; <strong>process </strong>&gt; <strong>present </strong>&gt; <strong>share&#8221;. Where does data.gov fall?</strong></p>
<p><strong>It can come as a surprise that they don&#8217;t touch the last 3 steps. Well, it certainly will be a surprise for anyone expecting the government to open a user-centric, one-stop-shop for data. Data.gov is certainly not a destination website for lay audiences.</strong></p>
<p>It doesn&#8217;t host the data either, however, its existence drives agencies to publish their datasets in compliance with its standards. So we can say that it indirectly addresses access.</p>
<p>So what it really is about is finding data. Currently, the site has two services to direct users to a dataset: a search engine and a catalogue. The browsable catalogue has only one layer of hierarchy, and while this is fine with their initial volume (47 datasets, around 200 as of end of June) that won&#8217;t suffice if their ambition is to host 100,000 federal data feeds.</p>
<p>All in all, it could be argued that data.gov doesn&#8217;t do much by itself. But what is interesting is what it enables others to do.</p>
<p>On the longer term, it will drive all agencies to publish their data under one publication standard. And if you have 100,000 datasets published under that standard, and if people use it to find them, then we will have a <em>de facto </em>industry standard to describe data. The consequences of that cannot be overestimated.</p>
<p>The other not obvious long-term advantage is what it will allow developer to create. There are virtually no technical barriers to creating interesting applications on top of these datasets. Chances are that some of these applications could change our daily lives. And they will be invented not by the government, but by individuals, researchers or entrepreneurs. quite something to be looking forward to.</p>
]]></content:encoded>
			<wfw:commentRss>/2009/06/30/new-data-services-3-datagov/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
		<item>
		<title>Google public data, Wolfram Alpha and data.gov</title>
		<link>/2009/05/25/google-public-data-wolfram-alpha-and-datagov/</link>
		<comments>/2009/05/25/google-public-data-wolfram-alpha-and-datagov/#respond</comments>
		<pubDate>Mon, 25 May 2009 16:18:53 +0000</pubDate>
		<dc:creator><![CDATA[jerome]]></dc:creator>
				<category><![CDATA[data publishing]]></category>
		<category><![CDATA[data.gov]]></category>
		<category><![CDATA[google.com]]></category>
		<category><![CDATA[many-eyes]]></category>
		<category><![CDATA[metadata]]></category>
		<category><![CDATA[open data]]></category>
		<category><![CDATA[public data]]></category>
		<category><![CDATA[swivel]]></category>
		<category><![CDATA[wolfram alpha]]></category>

		<guid isPermaLink="false">http://jckr.github.io/blog/?p=135</guid>
		<description><![CDATA[This last two weeks, three high-profile data-related services have been released: google&#8217;s public data, Wolfram&#124;Alpha and data.gov. In the next couple of posts I&#8217;m going to review all three. But before I&#8217;d like to go back to 2007, when Swivel.com and Many-eyes.com were released. Those 2 services allow users to publish their own data visualizations, <a class="read-more" href="/2009/05/25/google-public-data-wolfram-alpha-and-datagov/">&#8230;&#160;<span class="meta-nav">&#8594;</span></a>]]></description>
				<content:encoded><![CDATA[<p>This last two weeks, three high-profile data-related services have been released: google&#8217;s public data, Wolfram|Alpha and data.gov.</p>
<p><a href="http://www.google.com/search?hl=en&amp;gl=us&amp;q=unemployment+rate+santa+clara&amp;aq=f&amp;oq=&amp;aqi=g1"><img class="aligncenter size-medium wp-image-137" title="google's public data" src="http://jckr.github.io/blog/wp-content/uploads/2009/05/googlepublicdata-300x210.png" alt="google's public data" width="300" height="210" /></a><a href="http://www.wolframalpha.com/"><img class="aligncenter size-medium wp-image-138" title="Wolfram|alpha" src="http://jckr.github.io/blog/wp-content/uploads/2009/05/wolframalpha-275x300.png" alt="Wolfram|alpha" width="275" height="300" /></a></p>
<p><a href="http://data.gov/"><img class="aligncenter size-medium wp-image-136" title="data.gov screenshot" src="http://jckr.github.io/blog/wp-content/uploads/2009/05/datagov-300x223.png" alt="data.gov screenshot" width="300" height="223" /></a>In the next couple of posts I&#8217;m going to review all three.</p>
<p>But before I&#8217;d like to go back to 2007, when Swivel.com and Many-eyes.com were released.</p>
<p>Those 2 services allow users to publish their own data visualizations, based on datasets uploaded by themselves or by others. At the OECD, we had used the services extensively, uploading hundreds of datasets and creating that many visualizations.</p>
<p>At the end of the day, my main gripe with both services was never the visualization proper, or the interface, or any of the services to the data publisher &#8211; which the developers knew to be highly perfectible. No, what bothered me was the navigation within the site and how all the datasets were organized. There wasn&#8217;t any way to group your datasets or visualizations, then to group these groupings. Sure, they had an author name attached to them, and later, a theme, so it was possible to see all datasets from a specific author, or about a specific theme. But at the end of the day, that was a very long list, so the top titles received all the exposure, and the others, none. And indeed, we realized that some of our data objects got all the traffic, while others, not necessarily less interesting, had none &#8211; they were simply not seen.</p>
<p>My reaction to swivel and many-eyes was to tell them, you are not going to be able to allow users to search for data sets on your site. It&#8217;s too difficult and it&#8217;s not your focus. Forget about being a community site or a portal, and instead, allow users to share what they make on your sites in the environments they like. Allow them to download images, embed applets, you name it, but the navigation will have to happen on their site, not on yours.</p>
<p>So let&#8217;s see how this applies to these 3 new services.</p>
]]></content:encoded>
			<wfw:commentRss>/2009/05/25/google-public-data-wolfram-alpha-and-datagov/feed/</wfw:commentRss>
		<slash:comments>0</slash:comments>
		</item>
	</channel>
</rss>
